# Data-Lakehouse-with-Databricks
I set up a Dabricks cluster to execute a pipeline with PySpark. Databricks created its infrastructure using AWS CloudFormation. The dataset is available at the Databricks Sample datasets and it is about music tracks. The PySpark pipeline created the schema and did the raw data ingestion. After were used SQL Language to transform and anlyse the dataset. The pipeline aimed to discover which artist publishes the most songs per year.

## Services provided:
- [x] Databricks cluster creation
- [x] Raw data ingestion with PySpark
- [x] Data transformation with SQL
- [x] Analytics with SQL

## Developed Skills:
- [x] PySpark
- [x]	SQL
- [x]	Databricks
- [x]	AWS CloudFormation

## Architecture Diagram:

<img src="/Architecture Diagram.png">

I made this diagram using [Diagrams.net](https://app.diagrams.net/)
